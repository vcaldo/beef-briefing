# Development environment - local machine
# Includes: telegram-bot, api-service, dashboard, postgres, llm-analyzer, ollama
version: '3.8'

services:
  postgres:
    build:
      context: ../apps/postgres
      dockerfile: Dockerfile
    container_name: beef-postgres-dev
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    ports:
      - "${DB_PORT}:5432"
    volumes:
      - postgres_data_dev:/var/lib/postgresql/data
    networks:
      - beef-dev-network
    restart: unless-stopped

  api-service:
    build:
      context: ../apps/api-service
      dockerfile: Dockerfile
    container_name: beef-api-service-dev
    environment:
      DB_HOST: postgres
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      DB_PORT: 5432
      API_PORT: ${API_PORT}
      OLLAMA_API_HOST: ollama
      OLLAMA_API_PORT: ${OLLAMA_PORT}
    ports:
      - "${API_PORT}:${API_PORT}"
    depends_on:
      - postgres
    networks:
      - beef-dev-network
    restart: unless-stopped

  telegram-bot:
    build:
      context: ../apps/telegram-bot
      dockerfile: Dockerfile
    container_name: beef-telegram-bot-dev
    environment:
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
      API_SERVICE_URL: http://api-service:${API_PORT}
    depends_on:
      - api-service
    networks:
      - beef-dev-network
    restart: unless-stopped

  dashboard:
    build:
      context: ../apps/dashboard
      dockerfile: Dockerfile
    container_name: beef-dashboard-dev
    environment:
      API_SERVICE_URL: http://api-service:${API_PORT}
      DASHBOARD_PORT: ${DASHBOARD_PORT}
    ports:
      - "${DASHBOARD_PORT}:${DASHBOARD_PORT}"
    depends_on:
      - api-service
    networks:
      - beef-dev-network
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: beef-ollama-dev
    environment:
      OLLAMA_HOST: 0.0.0.0:${OLLAMA_PORT}
    ports:
      - "${OLLAMA_PORT}:${OLLAMA_PORT}"
    volumes:
      - ollama_models_dev:/root/.ollama
    networks:
      - beef-dev-network
    restart: unless-stopped

  llm-analyzer:
    build:
      context: ../apps/llm-analyzer
      dockerfile: Dockerfile
    container_name: beef-llm-analyzer-dev
    environment:
      OLLAMA_HOST: http://ollama:${OLLAMA_PORT}

      CLOUD_API_HOST: api-service
      CLOUD_API_PORT: ${API_PORT}
    depends_on:
      - ollama
    networks:
      - beef-dev-network
    restart: unless-stopped

volumes:
  postgres_data_dev:
  ollama_models_dev:

networks:
  beef-dev-network:
    driver: bridge
